{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323ee605-cb58-41e7-bfaa-46352ec0a8df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1 (ACor) Properties of Stationary Models\n",
    "\n",
    "- **Main Idea :** *(Copy directly to overview notebook)*\n",
    "- **Questions :**\n",
    "- **Notation :** \n",
    "    1. z, observations\n",
    "    2. t, time step\n",
    "    3. z$_{t}$, observation at t\n",
    "    4. p(z$ _{t} $), probability distribution of some observation at t w/ a mean & standard deviation\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f16a51-e2e1-4cce-bb6f-98a2e3402f7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1.1 TS & Stochastic Processes (SP)\n",
    "- **Main Idea :**\n",
    "    - There are different types of TS. We'll only consider the **discrete** case but $ \\exists $ two more which are **continuous** and **successive**. **Discrete TS** can be determined by both 1) getting data at a *specific time* (ie : every 9 secs) & 2) collecting data *over time* (ie : days, months). To distinguish the two, think of multiple checker boards side-by-side. **Discrete TS** can be determined by both 1) getting data of any block on any board (ie : every 2 blocks across all the boards) & 2) getting the data of every board (so a sum of the each block). \n",
    "    - Authors emphasizes **discrete TS**, **Statistical TS**\n",
    "    \n",
    "- **Questions :**\n",
    "    1. How can I distinguish the differences between **accumalation** and **batch process**.\n",
    "    2. Can I say that **specific time** is at an exact instance at that point in time?\n",
    "    3. Can I think of **over time** as across some interval so like from x to y?\n",
    "    \n",
    "- **Terms :** \n",
    "    1. **Continuous** [a set of continuous observations at a variable interval]\n",
    "    2. **Discrete** [a set of discrete observations at a fixed/set interval; can be **stationary** [2.1.1]]\n",
    "    3. **Successive** [observations made at **equidistant** time intervals]\n",
    "    4. **Sampling** [get data at some specificied time]\n",
    "    5. **Accumalation** [collection of a variable over a period time]\n",
    "    6. **Deterministic** [if future values of a TS are exactly determined by z$_{t}$ = cos(2$\\pi$ * f * t)]\n",
    "    7. **Statistical TS** [also **nonderministic**; if future values of a TS are determined by a **probability distribution**]\n",
    "    8. **Stochastic Processes** [a process]\n",
    "    9. **Realization** []\n",
    "    10. **Time Series** [a set of observations generated sequentially over time]\n",
    "    11. **Batch process** [accumulated over the batch time]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef15267-e89e-428e-b616-72eaaaf5b7d1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.1.2 Stationary (SP)\n",
    "- **Main Idea :**\n",
    "    - Here, we are dealing w/ submodules of **stochastic processes** called **stationary processes** & **strictly stationary**. W/ the checkboards ex, let's assign a \"weight/value\" to each block. As I move across each block w/ **strictly stationary**, my \"weight\" doesn't change. $ \\therefore $, $ \\exists $ for **stochastic processes** a constant mean & constant variance w/ a (single) pr() distribution of p(z$ _{t} $). This is also true for both joint pr() distributions (1) p(z$_{t_1}$, z$ _{t_2} $) & (2) p(z$_{t}$, z$ _{t + k} $).\n",
    "    \n",
    "- **Questions :**\n",
    "    1. How can I improve my understanding of **stochastic processes**?\n",
    "    \n",
    "- **Terms :**\n",
    "    1. **Stationary processes** [a special class of **stochstic process** which is based on the assumption that the processs is in a particular state of statistical equilibrium]\n",
    "    2. **Statistical equilibrium** [various states]\n",
    "    3. **Strictly stationary** [of a **stochastic process**, if properties are unaffected when changing; short hand : z$_{t}$ = z$_{t+1}$]\n",
    "    4. **Spread** [from L to R, how far about is my distribution. If narrow, small distribution but if wide, large distribution]\n",
    "    5. **Histogram** []\n",
    "    6. **Autocovariance coefficient** [at lag k, it measures the covariance between 2 values (z$ {_t} $ and z$ {_t}{_+}{_k}) $, a distance *k* apart ]\n",
    "    7. **Autocorrelation** []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ac36d-111b-4698-9a46-6be291c66faf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.1.3 Positive Definiteness and Autocovariance (ACov) Matrix\n",
    "- **Main Idea :**\n",
    "    - PD deals w/ funcs being > 0 given some observation & a linear func for a **stationary process**. $ \\exists $ a few conditions... For **positive definiteness** to hold true for an **ACov Matrix**, the determinants & principle minors (of the **ACov Matrix**) MUST be > 0.\n",
    "    - **White noise** plays a role in the properties through **linear filtering operations**\n",
    "    \n",
    "- **Questions :**\n",
    "    1. Further explore mathematical properities of symmetrical Matrices\n",
    "    2. Practice finding the determine of a Matrix\n",
    "    3. Practice finding the principle minors of a Matrix\n",
    "    4. Do **autocovariance** & **autocorrelation** Matrices have to be square Matrices or can they function w/ out being a square Matrix?\n",
    "- **Terms :**\n",
    "    1. **Autocovariance Matrix** [a **covariance matrix** that's symmetric w/ constant (*stationary*) elements along any diagonal]\n",
    "    2. **Autocorrelation Matrix** [the corresponding matrix of the **autocovariance matrix** w/ the main diagonal being all 1s]\n",
    "    3. **Positve definite** [for any **stationary process**, both matrices - **ACov** & **ACor** - if the l's are ! all 0s in the variance of L$_t$]\n",
    "    3. **Normal distribution (also called Gaussian Process)** [if the pr() distribution of z$ {_t} $s associated w/ *any* set of times is a **multivariate normal distribution**]\n",
    "    4. **Weak stationarity** [a condition that a process passes; the moments up to some order *f* depend only on time differences; is considered a less restrictive requirement]\n",
    "    5. **Weakly stationarity (of order 2)** [a condition w/ the assumption that the mean is 0 & $ \\exists $ some variance w/ in a seq of **independent** & **identically distributed** random vars]\n",
    "    6. **Independent and identically distributed** []\n",
    "    7. **Uncorrelated** [**white noise** w/ conditions 0 mean & common variance has the same **ACov func** & is **weakly (2nd order) stationary**]\n",
    "    8. **Infinite linear (time-invariant)** []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e17cbd-bba9-43f0-934a-e98e0ab6c84b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.1.4 (ACov) and (ACor) Funcs\n",
    "- **Main Idea :**\n",
    "    - Of **autocovariance func** and **autocorrelation func** (both are **stochastic processes**), take in the **coefficients** of both **autocovariance** $ \\gamma_k $ and **autocorrelation** $ \\rho{_k} $ w/ some lag *k*, to produce a plot. The **autocorrelation func** is *symmetric* about 0, so plotting only the positive half is standard.\n",
    "    - Characteristics of a *normal* **stationary process z$ {_t} $** : mean and **autocovariance func** $ \\Leftrightarrow $ mean, variance, and **autocorrelation func**\n",
    "    \n",
    "- **Questions :**\n",
    "    1. What's meant by \"*symmetric* about 0\"?\n",
    "    2. Futher understand the math behind characteristics of a *normal* **stationary process** & the equivalence above\n",
    "    \n",
    "- **Terms :**\n",
    "    1. **Autocovariance func** [of the **stochastic process**, it's the plot of **autocovariance coefficient** vs the lag *k*]\n",
    "    2. **Autocorrelation func** [of the **stochastic process**, it's the plot of **autocorrelation coefficient** as a func of the lag *k*]\n",
    "    3. **Correlogram** [another name of the **autocorrelation** func]\n",
    "    4. **Normal stationary process** []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4d6549-85fd-4016-83f8-eff7da3dc634",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.1.5 Estimation of (ACov) Funcs\n",
    "- **Main Idea :**\n",
    "    - Goal is to obtain *estimates* of the mean and the **autocorrelations** of a finite TS w/ N observations. Need at least 50 observations, and a K (total **autocorrelations** as in k = 0, 1, ..., K) < N/4. The **autocorrelation function** is characterized by correlations that alternate in sign and tend to damp out with increasing lag.\n",
    "    \n",
    "- **Questions :**\n",
    "    1. What's meant by \"damp out\"?\n",
    "    2. Does \"damp out\" only occur when increasing lag? How about if lag is stable or decreasing?\n",
    "- **Terms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f156a78e-494b-4466-826c-e16a232aa3cc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.1.6 Standard Errors of (ACor) Estimates\n",
    "- **Main Idea :**\n",
    "- **Questions :**\n",
    "- **Terms :**\n",
    "    1. d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b38ae11-2256-4f5b-aeb3-48a323592e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
